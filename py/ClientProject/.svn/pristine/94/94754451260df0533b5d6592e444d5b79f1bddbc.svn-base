# -*- coding: utf-8 -*-
#单例测试导入路径
if __name__ == '__main__':
    import sys, os
    parent_path = os.path.dirname(os.getcwd())
    sys.path.append(parent_path)

from webparser.webparserbase import ParserBase
from serializ.htmlfile import *
from serializ.oracle import *
from bean.urlbean import *
from log.logger import *
import datetime

LOG=logging.getLogger()
LOG.handlers[0].setLevel(logging.INFO)
LOG.handlers[1].setLevel(logging.INFO)

################################
metadatas = ('RECMETAID',
         '题名',
         '来源链接',
         '小区名称',
         '所属区域',
         '小区链接',
         '楼栋名称',
         '地址',
         '建成年份',
         '总层数',
         '当前层',
         '朝向',
         '建筑面积',
         '使用面积',
         '产权性质',
         '装修情况',
         '户型',
         '卧室数量',
         '客厅数量',
         '卫生间数量',
         '厨房数量',
         '阳台数量',
         '单价',
         '总价',
         '挂牌时间',
         '房屋图片',
         '信息来源',
         '联系人',
         '所属公司',
         '联系电话',
         '纬度',
         '经度',
         '备注',
         '预留字段',
         '房源编号',
         '发布时间',
         '住宅类别',
         '建筑类别',
         '配套设施',
         '估价链接',
         '租金链接',
         '房屋标签',
         '交通状况',
         '街景地图场景ID',
         '地图链接',
         '楼盘详情和所属HTML',
         '楼盘物业类型',
         '楼盘绿化率',
         '楼盘物业费',
         '楼盘物业公司',
         '楼盘开发商',
         '本月均价',
         '楼盘价格走势',
         '小区详情走势图链接',
         '经纪人链接',
         '经纪人图片链接',
         '小区成交历史链接',
         '城市',
         '行政区',
         '数据来源',
         'STR_ORDER')                                                                          #65

def format_str(s):
    return s.replace("\r\n",'').replace("\n",'').replace(' ', '').replace("\t",'').replace("\r",'').replace('\xa0','').lstrip().replace('&nbsp;','')

import requests, re
from bs4 import BeautifulSoup, Tag

#解析中原地产真是成交数据
class wwwcentanetcom(ParserBase):
    headers = {'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.152 Safari/537.36 LBBROWSER', 'Connection': 'keep-alive'}
    htmlwrite = HtmlFile()

    def __init__(self):
        super(wwwcentanetcom, self).__init__()

    #加载城市页面列表
    def default(self, urlbase):
        LOG.info('中原交易采集范围')
        citys = (("http://bj.centanet.com/chengjiao/g", 100), #北京 100页
                 ("http://cd.centanet.com/chengjiao/g", 60),
                 ("http://cq.centanet.com/chengjiao/g", 60),
                 ("http://nj.centanet.com/chengjiao/g", 30),
                 ("http://sh.centanet.com/chengjiao/g", 200),
                 ("http://sz.centanet.com/chengjiao/g", 100),
                 ("http://tj.centanet.com/chengjiao/g", 92))
        i_order = urlbase.order+'0'
        ls = []
        for city in citys:
            for i in range(city[1]):
                ls.append(UrlBean("%s%d/" % (city[0], i+1), self.message('getpages'), order=i_order))
        return ls

    #解析城市二手房列表页
    def getpages(self, urlbase):
        LOG.info('centanetgetpages获得城市%s成交列表信息', urlbase.url)
        r = requests.get(urlbase.url, headers=self.headers, timeout=(3.05, 2.5))
        LOG.info('访问耗时:%.4f, url:%s', r.elapsed.microseconds/1000000, r.url)
        if(r.status_code != requests.codes.ok):
            LOG.warning('wwwcentanetcom %s 返回状态:%s', urlbase.url, r.status_code)
            return None
        html = r.text
        soup = BeautifulSoup(html, 'html.parser') #lxml
        tatle = soup.find_all('tr',attrs={'class':'js_point_list'})
        i_order = urlbase.order+'1'
        ls = []
        d = {}  #定义结果集合
        for tr in tatle:
            tatle_td = tr.find_all('td')
            if len(tatle_td) == 8:
                d['挂牌时间'] = tatle_td[0].text
                # print(d['挂牌时间'])
                XQ_name = tatle_td[1].find_all('span',attrs={'class':'js_map_animate'})
                for name in XQ_name:
                    name_tatle = name.find('a')
                    d['小区名称'] = name_tatle.text
                    d['户型'] = tatle_td[2].text
                    d['建筑面积'] = tatle_td[3].text
                    d['总价'] = tatle_td[4].text
                    d['单价'] = tatle_td[5].text
                    d['联系人'] = tatle_td[6].text
                    CX_url = tatle_td[7].find('a')
                    d['城市'] = re.findall('<span class="yhtext">(.*?)</span><i class="icon-arrow"></i>',html,re.S)[0]
                    if CX_url['href']:
                        Cx_lint = "%s%s" % ('/'.join(r.url.split('/')[:3]), CX_url['href'])
                        d['来源链接'] = Cx_lint
                        #page_lint = geturl(Cx_lint)
                        ls.append(UrlBean(Cx_lint, self.message('getitem'), key=Cx_lint, param=dict(d), order=i_order))
        return ls

    #解析详细页面信息
    def getitem(self, urlbase):
        LOG.info('centanetgetpages获得城市%s挂牌详细信息', urlbase.url)
        t1 = time.time()
        r = requests.get(urlbase.url, headers=self.headers, timeout=(3.05, 2.5))
        t2 = time.time()
        LOG.info('处理centanetgetpages请求getitem耗时:%f' % (t2-t1))
        LOG.info('访问耗时:%.4f, url:%s', r.elapsed.microseconds/1000000, r.url)
        #存储页面信息
        t1 = time.time()
        self.htmlwrite.save('%s\\%s\\%s' %(self.__class__.__name__, '真实成交', r.url.split('.')[0].split('/')[-1]), r.url, r.text)
        t2 = time.time()
        if(r.status_code != requests.codes.ok):
            LOG.warning('wwwcentanetcom %s 返回状态:%s', r.request.url, r.status_code)
            return
        t1 = time.time()
        html_lint = r.text
        soup_lint = BeautifulSoup(html_lint, 'html.parser') #lxml
        d = urlbase.param
        d['所属区域'] = re.findall('<span class="w_70 cGray">行&nbsp;&nbsp;政&nbsp;&nbsp;区：</span><p class="disinfo_r">(.*?)</a>',html_lint,re.S)[0]
        dr = re.compile(r'<[^>]+>',re.S)
        d['所属区域'] = re.sub(dr,'',d['所属区域'])
        d['地址'] = re.findall('<span class="w_70 cGray">地&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;址：</span>(.*?)</a>',html_lint,re.S)[0]
        d['地址'] = re.sub(dr,'',d['地址'])
        try:
            d['楼盘物业公司'] = re.findall('<span class="w_70 cGray">物业公司：</span><p class="disinfo_r">(.*?)</p>',html_lint,re.S)[0]
            d['楼盘开发商'] = re.findall('<span class="w_70 cGray">开&nbsp;&nbsp;发&nbsp;&nbsp;商：</span>(.*?)</p>',html_lint,re.S)[0]
            d['楼盘开发商'] = re.sub(dr,'',d['楼盘开发商'])
        except:
            d['楼盘物业公司'] = ''
            d['楼盘开发商'] = ''
        Xq_url = soup_lint.find('div',attrs={'class':'Mdetail_1'})
        Xq_url_lint = Xq_url.find('h2').find('a')
        if Xq_url_lint['href']:
            Xq_url_lint_1 = "%s%s" % ('/'.join(r.url.split('/')[:3]), Xq_url_lint['href'])
            d['小区链接'] = Xq_url_lint_1
            page_list = requests.get(Xq_url_lint_1, headers=self.headers, timeout=(3.05, 2.5))
            #page_list = geturl(Xq_url_lint_1)
            html_list = page_list.text
            soup_list = BeautifulSoup(html_list, 'html.parser')
            try:
                d['本月均价'] = re.findall('<span class="f666 f12">均价</span><b class="cRed priceNub mr6"><span>￥</span>(.*?)</b>',html_list,re.S)[0]
                d['建成年份'] = re.findall('<span class="f666">建造年代：</span><span class="f000">(.*?)年',html_list,re.S)[0]
                d['楼盘物业类型'] = re.findall('<li class="halfline"><s class="fourword">物业类型：</s> <b class="fourword">(.*?)</b>',html_list,re.S)[0]
                d['楼盘绿化率'] = re.findall('<li class="halfline"><s class="fourword">绿化率：</s> <b class="fourword">(.*?)</b>',html_list,re.S)[0]
                d['楼盘物业费'] = re.findall('<li class="halfline"><s class="fourword">物业费：</s> <b class="fourword">(.*?)</b>',html_list,re.S)[0]
            except:
                d['本月均价'] = ''
                d['建成年份'] = ''
                d['楼盘物业类型'] = ''
                d['楼盘绿化率'] = ''
                d['楼盘物业费'] = ''
            d['RECMETAID']=''
            d['题名']=''
            d['楼栋名称']=''
            d['总层数']=''
            d['当前层']=''
            d['朝向']=''
            d['使用面积']=''
            d['产权性质']=''
            d['装修情况']=''
            d['卧室数量']=''
            d['客厅数量']=''
            d['卫生间数量']=''
            d['厨房数量']=''
            d['阳台数量']=''
            d['房屋图片']=''
            d['信息来源']=''
            d['所属公司']=''
            d['联系电话']=''
            d['纬度']=''
            d['经度']=''
            d['备注']=''
            d['预留字段']=''
            d['房源编号']=''
            d['发布时间']=''
            d['住宅类别']=''
            d['建筑类别']=''
            d['配套设施']=''
            d['估价链接']=''
            d['租金链接']=''
            d['房屋标签']=''
            d['交通状况']=''
            d['街景地图场景ID']=''
            d['地图链接']=''
            d['楼盘详情和所属HTML']=''
            d['楼盘价格走势']=''
            d['小区详情走势图链接']=''
            d['经纪人链接']=''
            d['经纪人图片链接']=''
            d['小区成交历史链接']=''
            d['行政区']=''
            # x = format_str(d['RECMETAID'])+'\t'+format_str(d['题名'])+'\t'+format_str(d['来源链接'])+'\t'+format_str(d['小区名称'])+'\t'+format_str(d['所属区域'])+'\t'+format_str(d['小区链接'])+'\t'+format_str(d['楼栋名称'])+'\t'+format_str(d['地址'])+'\t'+format_str(d['建成年份'])+'\t'+format_str(d['总层数'])+'\t'+format_str(d['当前层'])+'\t'+format_str(d['朝向'])+'\t'+format_str(d['建筑面积'])
            # y = format_str(d['使用面积'])+'\t'+format_str(d['产权性质'])+'\t'+format_str(d['装修情况'])+'\t'+format_str(d['户型'])+'\t'+format_str(d['卧室数量'])+'\t'+format_str(d['客厅数量'])+'\t'+format_str(d['卫生间数量'])+'\t'+format_str(d['厨房数量'])+'\t'+format_str(d['阳台数量'])+'\t'+format_str(d['单价'])+'\t'+format_str(d['总价'])
            # z = format_str(d['挂牌时间'])+'\t'+format_str(d['房屋图片'])+'\t'+format_str(d['信息来源'])+'\t'+format_str(d['联系人'])+'\t'+format_str(d['所属公司'])+'\t'+format_str(d['联系电话'])+'\t'+format_str(d['纬度'])+'\t'+format_str(d['经度'])+'\t'+format_str(d['备注'])+'\t'+format_str(d['预留字段'])+'\t'+format_str(d['房源编号'])
            # w = format_str(d['发布时间'])+'\t'+format_str(d['住宅类别'])+'\t'+format_str(d['建筑类别'])+'\t'+format_str(d['配套设施'])+'\t'+format_str(d['估价链接'])+'\t'+format_str(d['租金链接'])+'\t'+format_str(d['房屋标签'])+'\t'+format_str(d['交通状况'])+'\t'+format_str(d['街景地图场景ID'])+'\t'+format_str(d['地图链接'])+'\t'+format_str(d['楼盘详情和所属HTML'])
            # q = format_str(d['楼盘物业类型'])+'\t'+format_str(d['楼盘绿化率'])+'\t'+format_str(d['楼盘物业费'])+'\t'+format_str(d['楼盘物业公司'])+'\t'+format_str(d['楼盘开发商'])+'\t'+format_str(d['本月均价'])+'\t'+format_str(d['楼盘价格走势'])+'\t'+format_str(d['小区详情走势图链接'])+'\t'+format_str(d['经纪人链接'])+'\t'+format_str(d['经纪人图片链接'])+'\t'+format_str(d['小区成交历史链接'])+'\t'+format_str(d['城市'])+'\t'+format_str(d['行政区'])
            for meta in d:
                d[meta] = format_str(d[meta])
            # print(x+'\t'+y+'\t'+z+'\t'+w+'\t'+q)
            # with open('zy_1101_2016-02-14.txt', 'a+', encoding='utf8') as f:
            #     f.write(x+'\t'+y+'\t'+z+'\t'+w+'\t'+q+'\n')
            #     f.flush()
            d['数据来源'] = 'zy'
            d['STR_ORDER']=urlbase.order
            self.completionlr(d, metadatas)
            MySqlEx.savecj(d, metadatas)
        t2 = time.time()
        LOG.info('解析页面耗时:%f' % (t2-t1))

if __name__ == '__main__':
    wwwcentanetcom = wwwcentanetcom()
    page = wwwcentanetcom.default(UrlBase('http://www.centanet.com', 'wwwcentanetcom',order='1603070948'))[0]
    item = wwwcentanetcom.getpages(UrlBean('http://bj.centanet.com/chengjiao/g1', 'wwwcentanetcom#getpages', order='16030709480'))[0]
    wwwcentanetcom.getitem(item)
    #wwwcentanetcom.getitem(UrlBean('http://bj.centanet.com/chengjiao/160221101701ab7e4d03b0e7088b39fa.html', 'wwwcentanetcom#getitem', order='160307094801'))